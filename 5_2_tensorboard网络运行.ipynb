{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0Test accuracy0.8233\n",
      "Iter 1Test accuracy0.8607\n",
      "Iter 2Test accuracy0.899\n",
      "Iter 3Test accuracy0.9044\n",
      "Iter 4Test accuracy0.908\n",
      "Iter 5Test accuracy0.9098\n",
      "Iter 6Test accuracy0.9115\n",
      "Iter 7Test accuracy0.9126\n",
      "Iter 8Test accuracy0.9156\n",
      "Iter 9Test accuracy0.9156\n",
      "Iter 10Test accuracy0.9173\n",
      "Iter 11Test accuracy0.9188\n",
      "Iter 12Test accuracy0.9192\n",
      "Iter 13Test accuracy0.9197\n",
      "Iter 14Test accuracy0.9205\n",
      "Iter 15Test accuracy0.9209\n",
      "Iter 16Test accuracy0.9207\n",
      "Iter 17Test accuracy0.9216\n",
      "Iter 18Test accuracy0.9209\n",
      "Iter 19Test accuracy0.9208\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "batch_size = 100  # 可优化\n",
    "n_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "#c参数概要\n",
    "def variable_summaries(var):  # 在tensorboard中显示var的相关属性值\n",
    "    with tf.name_scope(\"summaries\"):\n",
    "        mean = tf.reduce_mean(var)  # 平均值\n",
    "        tf.summary.scalar(\"mean\", mean)\n",
    "        with tf.name_scope(\"stddev\"):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar(\"stddev\", stddev)  # 标准差\n",
    "        tf.summary.scalar(\"max\", tf.reduce_max(var))  # 最大值\n",
    "        tf.summary.scalar(\"min\", tf.reduce_min(var))  # 最小值\n",
    "        tf.summary.histogram(\"histogram\", var)  # 直方图\n",
    "\n",
    "#命名空间\n",
    "with tf.name_scope(\"input\"):\n",
    "    x = tf.placeholder(tf.float32, [None, 784],name=\"x-input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10] ,name=\"y-input\")\n",
    "\n",
    "# 创建简单神经网络（可优化）\n",
    "with tf.name_scope(\"layout\"):\n",
    "    with tf.name_scope(\"wights\"):\n",
    "        W = tf.Variable(tf.zeros([784, 10]),name=\"W\")\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope(\"biases\"):\n",
    "        b = tf.Variable(tf.zeros([10]),name=\"b\")\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope(\"wx_plus_b\"):\n",
    "        wx_plus_b=tf.matmul(x, W) + b\n",
    "    with tf.name_scope(\"predict\"):\n",
    "        predict = tf.nn.softmax(wx_plus_b)  # softmax将输出信号转化为概率值（10个概率值）\n",
    "\n",
    "# 可使用交叉熵代价函数来优化\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=predict))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "# 使用梯度下降法训练，使得loss最小（#可优化）\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    # 比较概率最大的标签是否相同，结果存放在一个布尔型列表中\n",
    "    with tf.name_scope(\"correct_predict\"):\n",
    "        correct_predict = tf.equal(tf.argmax(y, 1), tf.argmax(predict, 1))  # argmax返回一维张量中最大值所在的位置\n",
    "    # 求准确率\n",
    "    with tf.name_scope(\"accu\"):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))  # reduce_mean求平均值\n",
    "        tf.summary.scalar(\"accuracy\",accuracy)\n",
    "               \n",
    "# 合并所有summar\n",
    "merged=tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "    for epoch in range(20):  # 可优化\n",
    "        for batch in range(n_batch):  # 把所有图片训练一次\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            summary,_=sess.run([merged,train_step], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "        #  用测试数据来检验训练好的模型\n",
    "        writer.add_summary(summary,epoch)\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Iter \" + str(epoch) + \"Test accuracy\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
